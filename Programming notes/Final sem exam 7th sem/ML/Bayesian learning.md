1. Bayesian probability talks about partial beliefs.
2. Bayesian estimation calculates the validity of a proposition.
3. It calculates validity based on 1. Prior estimate of its probability and new relevant evidence.
![[Pasted image 20231213131621.png]]
![[Pasted image 20231213131737.png]]
<iframe width="560" height="315" src="https://www.youtube.com/embed/VIj6xS937E4?si=KPOKOcuOgmj5tlbX" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>


![[Pasted image 20231213132336.png]]
![[Pasted image 20231213132535.png]]
![[Pasted image 20231213132853.png]]
![[Pasted image 20231213133151.png]]

$P(Y) == P(Sunny | yes)$

![[Pasted image 20231213133458.png]]
![[Pasted image 20231213133640.png]]
> We ignore  denominator  because it is always constant
![[Pasted image 20231213133813.png]]

![[Pasted image 20231213133910.png]]
![[Pasted image 20231213134021.png]]
### Base theorem
![[Pasted image 20231206185540.png]]
- P(h/d) => probability of h given d
- p(D / h) => probability of D given h
- p(h) => prior probability
- P(D) => probability of D (new relevant evidence)

### Naive Bayes Classifier
- supervised learning algorithm
- Based on base theorem
- Naive stands for all the variables are independent.
![[Pasted image 20231206191126.png]]
![[Pasted image 20231206191502.png]]
