- In case of random forests decision trees are parallelly connected
- in case of boosting techniques decision trees are sequentially connected.

![[Pasted image 20231214173419.png]]

- These d trees are weak learners
- DT1 keeps correctly predicted outputs with itself and wrongly predicted outputs are forwarded to dt2.
- Same is for dt2.
- When we combine the decision trees it becomes strong learner.
- Weak learners => haven't learnt much from the training dataset.
- In randome 

Lasso regression
regfit
bagging
